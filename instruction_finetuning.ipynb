{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_NLMFtNONpZ"
      },
      "source": [
        "A GPT MODEL FROM SCRATCH TO GENERATE TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YIme4udAPY3f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import tiktoken\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mAPZN5CNuA1i"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9DtA6S_fuEMq"
      },
      "outputs": [],
      "source": [
        "# for reproducible results\n",
        "m_seed = 369"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "seEKhwqLOWCH"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # vocabulary size\n",
        "    \"context_length\": 1024, # context length\n",
        "    \"emb_dim\": 768,         # embedding dimension\n",
        "    \"n_heads\": 12,          # number of attention heads\n",
        "    \"n_layers\": 12,         # number of layers / transformers\n",
        "    \"drop_rate\": 0.1,       # dropout rate\n",
        "    \"qkv_bias\": True        # Query-Key-Value bias\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02k7pIjjPwdt"
      },
      "source": [
        "LAYER NORMALISATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fbs5iY34umSz"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kO_8LEbYGZG"
      },
      "source": [
        "FEED FORWARD NETWORK USING GELU FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ui8fIQi1uuS3"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "         ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckWc3HItRANL"
      },
      "source": [
        "MULTIHEAD ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eW1_RaCwRCXh"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.d_out = d_out\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "\n",
        "        self.out_proj = nn.Linear(d_in, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            'mask',\n",
        "            torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        queries = self.W_query(x)\n",
        "        keys = self.W_key(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        queries = queries.transpose(1, 2)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        attn_scores = attn_scores.masked_fill(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context_vecs = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        context_vecs = context_vecs.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vecs = self.out_proj(context_vecs)\n",
        "\n",
        "        return context_vecs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmMZvbQTRknn"
      },
      "source": [
        "TRANSFORMER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6p82E6JrRmTP"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "        self.attn = MultiHeadAttention(\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"]\n",
        "        )\n",
        "\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaRXtysiRn7h"
      },
      "source": [
        "GPT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "VziG00o2RtfV"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxWjRCFQvUZm"
      },
      "source": [
        "CREATING GPT2 SMALL INSTANCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vFhaEbLKvYO5"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(m_seed)\n",
        "\n",
        "gpt = GPTModel(GPT_CONFIG_124M)\n",
        "gpt.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tzCImUjvctu"
      },
      "source": [
        "DOWNLOAD TRAINED WEIGHTS FROM OPENAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "5xPrwGcbvhEq",
        "outputId": "6caeeee6-a23e-4fe7-9047-100492464630"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8a947df1-e234-40a2-9f05-d2e397e7c6ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8a947df1-e234-40a2-9f05-d2e397e7c6ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving download_gpt2.py to download_gpt2.py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdaJsSY9vnjY",
        "outputId": "6e0d605a-afaa-44e2-e352-80b94baeed6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 232kiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.21MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 144kiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:37<00:00, 13.3MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 6.99MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.62MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.61MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from download_gpt2 import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"models_gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JP9xi-DFRzui"
      },
      "outputs": [],
      "source": [
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return nn.Parameter(torch.tensor(right))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Mhdbr2zzTXcg"
      },
      "outputs": [],
      "source": [
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params[\"wpe\"])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params[\"wte\"])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "\n",
        "        gpt.trf_blocks[b].attn.W_query.weight = assign(gpt.trf_blocks[b].attn.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].attn.W_key.weight = assign(gpt.trf_blocks[b].attn.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].attn.W_value.weight = assign(gpt.trf_blocks[b].attn.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "\n",
        "        gpt.trf_blocks[b].attn.W_query.bias = assign(gpt.trf_blocks[b].attn.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].attn.W_key.bias = assign(gpt.trf_blocks[b].attn.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].attn.W_value.bias = assign(gpt.trf_blocks[b].attn.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].attn.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].attn.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].attn.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].attn.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(gpt.trf_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(gpt.trf_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(gpt.trf_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(gpt.trf_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "        gpt.final_norm.scale = assign(gpt.final_norm.scale, params['g'])\n",
        "        gpt.final_norm.shift = assign(gpt.final_norm.shift, params['b'])\n",
        "        gpt.out_head.weight = assign(gpt.out_head.weight, params['wte'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SLR_6fATvxll"
      },
      "outputs": [],
      "source": [
        "load_weights_into_gpt(gpt, params)\n",
        "gpt.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJfpbIUaTcfp"
      },
      "source": [
        "GENERATING TEXT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OFYs6C88Tgxz"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    text = tokenizer.decode(flat.tolist())\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3VaUYYBrwAHv"
      },
      "outputs": [],
      "source": [
        "def generate(model, idx, max_new_tokens, context_size, temperature=None, top_k=None, eos_id=None):\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        if top_k is not None:\n",
        "            top_k_logits, _ = torch.topk(logits, top_k)\n",
        "            min_val = top_k_logits[:, -1]\n",
        "            logits = torch.where(\n",
        "                condition=logits < min_val,\n",
        "                input=torch.tensor(float(\"-inf\")).to(logits.device),\n",
        "                other=logits\n",
        "            )\n",
        "\n",
        "        t = temperature\n",
        "        if t is None:\n",
        "            t = 0.0\n",
        "\n",
        "        if t > 0.0:\n",
        "            logits = logits / t\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        if idx_next == eos_id:\n",
        "            break\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCQRzWHzTp0N",
        "outputId": "e54b8e7c-dc9b-4cfb-ed92-f58b503b7aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text for t = 0.5:\n",
            " I like the way you look at it.\"  \"It's not like you're saying anything about the people I'm with.\"  \"But it's not like you're saying anything about me.\"  \"But I think you're just saying what you like\n",
            "Output text for t = 0.7:\n",
            " I like the way you look at it.\"  Hornett, who had been playing outside linebacker at the time, became interested in the game and played only 12 games in four seasons at Texas.\n",
            "Output text for t = 0.9:\n",
            " I like the way you look,\" the woman said.\n",
            "Output text for t = 1.1:\n",
            " I like the way you look,\" the woman added about what she would find in her apartment.\n",
            "Output text for t = 1.3:\n",
            " I like the way you look,\" Sosa recalled about what had happened after the man pulled his dog to the street, where he asked to stay with his dog.\n",
            "Output text for t = 1.5:\n",
            " I like the way you look,\" Sosa recalled about what had happened after the man pulled his dog to its handler's front yard on Wednesday night.\n"
          ]
        }
      ],
      "source": [
        "for t_10 in range(5, 16, 2):\n",
        "    temperature =  t_10 / 10\n",
        "\n",
        "    torch.manual_seed(m_seed)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(\"I like the way you\", tokenizer).to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        top_k=50,\n",
        "        temperature=temperature,\n",
        "        eos_id=13 # dot(.)\n",
        "    )\n",
        "\n",
        "    # replace \"\\n\" to make output more compact\n",
        "    text = token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \")\n",
        "    print(f\"Output text for t = {temperature}:\\n\", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmLfOwz7zOx-",
        "outputId": "4174b47e-7a14-4941-e9ab-0884003b73ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text for t = 0.5:\n",
            " My hobby is to build a simple and simple game using the latest technologies.\n",
            "Output text for t = 0.7:\n",
            " My hobby is to build small, high-quality LED's, and I've been doing this for over 5 years now.\n",
            "Output text for t = 0.9:\n",
            " My hobby is to build small, high-quality LED's as they work.\n",
            "Output text for t = 1.1:\n",
            " My hobby is to build small and fast wireless charging stations in my home gardens.\n",
            "Output text for t = 1.3:\n",
            " My hobby is to help small and moderate kids navigate what life as a grown man should be like with no expectations placed upon them.\"  What I am proud of is that as much as I hope to give my fellow American children one day of a good life it is\n",
            "Output text for t = 1.5:\n",
            " My hobby is to help small and moderate kids navigate what life as a grown man should be like with no expectations placed upon them.\"  What I am proud of is that as much as I hope our movement could turn away from the traditional notions that young people tend to\n"
          ]
        }
      ],
      "source": [
        "for t_10 in range(5, 16, 2):\n",
        "    temperature =  t_10 / 10\n",
        "\n",
        "    torch.manual_seed(m_seed)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(\"My hobby is to\", tokenizer).to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        top_k=50,\n",
        "        temperature=temperature,\n",
        "        eos_id=13 # dot(.)\n",
        "    )\n",
        "\n",
        "    # replace \"\\n\" to make output more compact\n",
        "    text = token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \")\n",
        "    print(f\"Output text for t = {temperature}:\\n\", text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDTf7MnazX8A",
        "outputId": "f89fdaf9-0995-4792-f92b-134604d151b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output text for t = 0.5:\n",
            " Honesty is the best way to know what's going on in the world,\" he said.\n",
            "Output text for t = 0.7:\n",
            " Honesty is the best way to know what's going on in the world,\" he added.\n",
            "Output text for t = 0.9:\n",
            " Honesty is the best way to know what's about to happen as a manager.\n",
            "Output text for t = 1.1:\n",
            " Honesty is the best way to know what's about to happen as a manager.\n",
            "Output text for t = 1.3:\n",
            " Honesty is the best way to know when or where people are taking action -- but there might be reasons to keep your hand at the door.\n",
            "Output text for t = 1.5:\n",
            " Honesty is the best way to know you know about what's taking place -- but if you let somebody down right away...what kind of message does it send...that it gets you down? What a waste of time and money....you want proof that they lied? Oh\n"
          ]
        }
      ],
      "source": [
        "for t_10 in range(5, 16, 2):\n",
        "    temperature =  t_10 / 10\n",
        "\n",
        "    torch.manual_seed(m_seed)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(\"Honesty is the best\", tokenizer).to(device),\n",
        "        max_new_tokens=50,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        top_k=50,\n",
        "        temperature=temperature,\n",
        "        eos_id=13 # dot(.)\n",
        "    )\n",
        "\n",
        "    # replace \"\\n\" to make output more compact\n",
        "    text = token_ids_to_text(token_ids, tokenizer).replace(\"\\n\", \" \")\n",
        "    print(f\"Output text for t = {temperature}:\\n\", text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTRUCTION FINETUNING"
      ],
      "metadata": {
        "id": "LAvLaMCKYxqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import urllib\n",
        "import ssl\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    ssl_context = ssl.create_default_context()\n",
        "    ssl_context.check_hostname = False\n",
        "    ssl_context.verify_mode = ssl.CERT_NONE\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "    else:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text_data = file.read()\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"Number of entries:\", len(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM8Nwf3QY2lv",
        "outputId": "16fe8dd0-e985-47d1-adf1-652925f651ec"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of entries: 1100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example entry:\\n\", data[50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Yc1xZcCY3VD",
        "outputId": "26b30da2-62c2-4596-aff9-64a3debf3996"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example entry:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONVERTING INSTRUCTION INTO ALPACA FORMAT"
      ],
      "metadata": {
        "id": "3H2CNTASY-_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ],
      "metadata": {
        "id": "rrs6UP5vZCv6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Lwbm8lZJLe",
        "outputId": "be5da4ba-2590-4677-91d9-6dbd8cb70df7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SPLITING DATASET INTO TRAIN-TEST-VALIDATION"
      ],
      "metadata": {
        "id": "-IY33NpwZNwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(data) * 0.85)  # 85% for training\n",
        "test_portion = int(len(data) * 0.1)    # 10% for testing\n",
        "val_portion = len(data) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ],
      "metadata": {
        "id": "0FwCfkwFZTzW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjU7drIFZWEG",
        "outputId": "bc84952b-69ed-418e-b09b-92df65d4c9a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 935\n",
            "Validation set length: 55\n",
            "Test set length: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 2 - ORGANIZING DATA INTO TRAINING BATCHES"
      ],
      "metadata": {
        "id": "gqYSEEYcZfIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "metadata": {
        "id": "tH0zNfheZpQi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLiOHJ4cZviu",
        "outputId": "6e6f45e4-c98b-4883-c231-c349dc4124af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ],
      "metadata": {
        "id": "hm6TUuj5Z9nd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of padding inputs to same length"
      ],
      "metadata": {
        "id": "VGAIKLr6aLdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hHSZ9RTaQh0",
        "outputId": "4fd24f37-0336-4933-cbc4-364b575fe2c8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING TARGET TOKEN IDS FOR TRAINING"
      ],
      "metadata": {
        "id": "bkZcUxb1aYKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "OgMDWWv-afDZ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TXZdvgaafmq",
        "outputId": "dffbbcae-d99e-4d97-a271-44fc8c5ec532"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # New: Optionally truncate to maximum sequence length\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ],
      "metadata": {
        "id": "OuUxSWfbaiav"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MASKING OUT PADDED TOKENS"
      ],
      "metadata": {
        "id": "XfFxPf4UbBiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kE09M4ras73",
        "outputId": "16bbee65-b786-4181-9e31-3ee550fccbf5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],  # 1st training example\n",
        "     [-0.5, 1.5]]  # 2nd training example\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsXoPqMyavub",
        "outputId": "aaf994e1-6334-44ba-b0d7-162f2d35402c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 3 - CREATING DATALOADERS FOR INSTRUCTION DATASET"
      ],
      "metadata": {
        "id": "mXHDfisTbO-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8fEDbEZbUiR",
        "outputId": "502f65d6-64c1-4510-fdd3-da256ab97237"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
      ],
      "metadata": {
        "id": "r_t5DVrMbfTX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ],
      "metadata": {
        "id": "9SHCqBEkbqQf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp_nQOKObs0x",
        "outputId": "db6f7537-58c5-453b-e143-9f2354d70c01"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 4 - LOADING A PRETRAINED LLM"
      ],
      "metadata": {
        "id": "3atMe5Ukb3Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from download_gpt2 import download_and_load_gpt2\n",
        "\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"models_gpt2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk9QBYgucDcs",
        "outputId": "9c84ffc1-8d73-4a26-a1ba-31efff62b1a2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/checkpoint\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/encoder.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/hparams.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/model.ckpt.data-00000-of-00001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/model.ckpt.index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/model.ckpt.meta\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and up-to-date:  models_gpt2/124M/vocab.bpe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's assess the performance by comparing its output with expecte response."
      ],
      "metadata": {
        "id": "Tgg7gCHOdE7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG7ddD-acqxV",
        "outputId": "294ec594-30bc-4559-b9d7-739d34f3bf7c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=35,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        #top_k=50,\n",
        "        eos_id=13 # dot(.)\n",
        "    )\n",
        "text = token_ids_to_text(token_ids, tokenizer)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkjrjiPydDV7",
        "outputId": "0daa842f-86a7-4f87-85ac-386a92254909"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the output, the pretrained model is not yet capable of correctly following the given instruction.\n",
        "\n",
        "It simply repeats the original input sentence and part of the instruction, failing to convert the active sentence to passive voice as requested."
      ],
      "metadata": {
        "id": "sgqGVGJOe4Ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 5 - FINETUNING LLM ON INSTRUCTION DATA"
      ],
      "metadata": {
        "id": "DboqeauPfORe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n"
      ],
      "metadata": {
        "id": "FLbWcbyOfjZs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, gpt, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, gpt, device, num_batches=5)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcqDyFWIfSzB",
        "outputId": "25ba09b4-97e3-4809-c311-7e93e62f643c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 4.1671394348144535\n",
            "Validation loss: 4.050935888290406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ],
      "metadata": {
        "id": "y5wUrrpjgHkb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "U1_CFacegf4L"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "\n",
        "    ###Input batch:\n",
        " ###tensor([[6109, 3626, 6100,  345],\n",
        "        ##[6109, 1110, 6622,  257]])\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond) ### batch, n_tokens, vocab_size\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "X9xDCYrhg2uH"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(gpt.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 1\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    gpt, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIXOiNVMfX2N",
        "outputId": "8e81d0db-d32c-4d1d-c52d-32679e298074"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.497, Val loss 0.772\n",
            "Ep 1 (Step 000005): Train loss 0.637, Val loss 0.816\n",
            "Ep 1 (Step 000010): Train loss 0.538, Val loss 0.829\n",
            "Ep 1 (Step 000015): Train loss 0.592, Val loss 0.831\n",
            "Ep 1 (Step 000020): Train loss 0.516, Val loss 0.838\n",
            "Ep 1 (Step 000025): Train loss 0.514, Val loss 0.841\n",
            "Ep 1 (Step 000030): Train loss 0.568, Val loss 0.849\n",
            "Ep 1 (Step 000035): Train loss 0.554, Val loss 0.839\n",
            "Ep 1 (Step 000040): Train loss 0.524, Val loss 0.836\n",
            "Ep 1 (Step 000045): Train loss 0.510, Val loss 0.842\n",
            "Ep 1 (Step 000050): Train loss 0.545, Val loss 0.856\n",
            "Ep 1 (Step 000055): Train loss 0.669, Val loss 0.868\n",
            "Ep 1 (Step 000060): Train loss 0.552, Val loss 0.864\n",
            "Ep 1 (Step 000065): Train loss 0.540, Val loss 0.848\n",
            "Ep 1 (Step 000070): Train loss 0.450, Val loss 0.821\n",
            "Ep 1 (Step 000075): Train loss 0.479, Val loss 0.823\n",
            "Ep 1 (Step 000080): Train loss 0.535, Val loss 0.845\n",
            "Ep 1 (Step 000085): Train loss 0.454, Val loss 0.849\n",
            "Ep 1 (Step 000090): Train loss 0.514, Val loss 0.832\n",
            "Ep 1 (Step 000095): Train loss 0.460, Val loss 0.843\n",
            "Ep 1 (Step 000100): Train loss 0.469, Val loss 0.840\n",
            "Ep 1 (Step 000105): Train loss 0.496, Val loss 0.819\n",
            "Ep 1 (Step 000110): Train loss 0.495, Val loss 0.799\n",
            "Ep 1 (Step 000115): Train loss 0.475, Val loss 0.778\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The chef cooked the meal every day.  \n",
            "Training completed in 0.63 minutes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N9tnZt2jf2j9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Oiye_wsThJ4l",
        "outputId": "81c7f330-b573-4220-e76c-a6994d8b3253"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6 - EXTRACTING AND SAVING RESPONSE"
      ],
      "metadata": {
        "id": "DlYnjL7QhR6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        ")\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
        "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1VNXcgehWQo",
        "outputId": "d9ca197d-dc0e-4c80-cfbb-51d7d1d6c300"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "Correct response:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "Model response:\n",
            ">> The car is a fast car.<|endoftext|>\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "Correct response:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "Model response:\n",
            ">> The type of cloud typically associated with thunderstorms is the active component cloud.<|endoftext|>\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "Correct response:\n",
            ">> Jane Austen.\n",
            "\n",
            "Model response:\n",
            ">> The author of 'Pride and Prejudice' is Robert Graves.<|endoftext|>\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=gpt,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05OJYjEkhZCv",
        "outputId": "f146ad03-d613-45f9-c878-f18701304828"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:41<00:00,  2.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlN-3PGih0SL",
        "outputId": "753e1185-19ad-41ab-8990-50d5fb812b7f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a cheetah.<|endoftext|>'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(gpt.state_dict(), file_name)\n",
        "print(f\"Model saved as {file_name}\")\n",
        "\n",
        "# Load model via\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX4henM0iGSs",
        "outputId": "38d4c161-b289-4599-85c5-47542f4314ff"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as gpt2-medium355M-sft.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xvi-_kFCiUBL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}